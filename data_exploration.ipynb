{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e442766-3059-40bf-ae4d-992db9d67fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "PROJECT_01_ROOT = \".\"\n",
    "DATA_DIR = Path(PROJECT_01_ROOT).joinpath(\"CreditApproval\")\n",
    "\n",
    "training_data = pd.read_csv(DATA_DIR.joinpath(\"training.data\"), header=None)\n",
    "test_data = pd.read_csv(DATA_DIR.joinpath(\"test.data\"), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc898063-3661-43d2-9efb-e8125ec04709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f01c97-9754-40fa-9996-ab12e2b435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"A\" + str(i) for i in range(1, 17)] # A1 - A16\n",
    "training_data.columns = column_names\n",
    "test_data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af08dffc-5af6-4809-bd7a-d12c13c4ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull labels off datasets\n",
    "training_labels = training_data[\"A16\"]\n",
    "test_labels = test_data[\"A16\"]\n",
    "\n",
    "clean_training = training_data.drop(\"A16\", axis=1)\n",
    "clean_test = test_data.drop(\"A16\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409058bd-1100-45a1-9df2-15c89140e7ac",
   "metadata": {},
   "source": [
    "`training_data` will not be mutated. I will make copies and manipulate those to determine median values.\n",
    "\n",
    "`clean_training` will be mutated to replace missing values with median values for appropriate columns. \n",
    "\n",
    "The below function handles updating attributes with their median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e5533a-e95a-497c-9161-5e270009466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attribute_w_median(attribute, is_numeric):\n",
    "    \"\"\"fills missing w median value for attribute, returns updated column\"\"\"\n",
    "    # get a copy of dataset which lacks the missing values\n",
    "    training_copy = training_data.copy()\n",
    "    if not is_numeric:\n",
    "        # cut missing values from copied training set when finding median\n",
    "        training_copy = training_copy[training_copy[attribute] != \"?\"]\n",
    "        attribute_values = training_copy[attribute].sort_values()\n",
    "        attribute_median = attribute_values[len(attribute_values) // 2]\n",
    "        \n",
    "        # return col from original training set with replacement\n",
    "        return training_data[attribute].replace(\"?\", attribute_median)\n",
    "    else:\n",
    "        training_copy[attribute] = pd.to_numeric(training_copy[attribute], errors=\"coerce\")\n",
    "        attribute_median = training_copy[attribute].median()\n",
    "        training_copy[attribute] = training_copy[attribute].fillna(attribute_median)\n",
    "        return training_copy[attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f71f91b-f729-4b24-a71d-fc8ee8b936b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1', 'A2', 'A4', 'A5', 'A6', 'A7', 'A14']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing_vals = training_data.columns[training_data.eq(\"?\").any(axis=0)].tolist()\n",
    "cols_with_missing_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e5473ea-9378-47b4-bb3b-6d81b238130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below dict includes keys for each column with missing values\n",
    "# the key is attribute name and value represents whether it is_numeric\n",
    "missing_attributes = {\n",
    "    \"A1\": False,\n",
    "    \"A2\": True,\n",
    "    \"A4\": False,\n",
    "    \"A5\": False,\n",
    "    \"A6\": False,\n",
    "    \"A7\": False,\n",
    "    \"A14\": True,\n",
    "}\n",
    "\n",
    "# call my custom function to update all columns in the clean_training df\n",
    "for attribute, is_numeric in missing_attributes.items():\n",
    "    filled_column = update_attribute_w_median(attribute, is_numeric)\n",
    "    clean_training[attribute] = filled_column\n",
    "\n",
    "for attribute, is_numeric in missing_attributes.items():\n",
    "    filled_column = update_attribute_w_median(attribute, is_numeric)\n",
    "    clean_test[attribute] = filled_column\n",
    "\n",
    "assert clean_training[\"A14\"].dtype == 'float64'\n",
    "assert clean_test[\"A14\"].dtype == 'float64'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b01e6-4ed8-4e37-bdd4-a92d9d9aa6b6",
   "metadata": {},
   "source": [
    "At this stage, `clean_training` and `clean_training` have been updated to replace all missing values with the appropriate median value. Now we can extract the datasets which will be relevant to our decision tree creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18ac3c45-0cfa-40fc-89a6-b994c6812755",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def sequentially_cross_validate(model, examples, labels, k=10):    \n",
    "    fold_size = len(examples) // k\n",
    "    # print(f\"cv {len(examples)} across {k} sets. folds are {fold_size} examples.\")\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = -1\n",
    "    \n",
    "    for i in range(k):\n",
    "        # determine sequential indices for validation set\n",
    "        v_start = i * fold_size\n",
    "        v_end = (i + 1) * fold_size if i != k-1 else len(examples)\n",
    "        \n",
    "        X_validation = examples.iloc[v_start:v_end]\n",
    "        y_validation = labels.iloc[v_start:v_end]\n",
    "\n",
    "        # grab remaining data for training set\n",
    "        X_train = pd.concat([examples.iloc[:v_start], examples.iloc[v_end:]])\n",
    "        y_train = pd.concat([labels.iloc[:v_start], labels.iloc[v_end:]])\n",
    "        \n",
    "        # print(f\"Fold {i}\\n\\tValidation from {v_start} to {v_end - 1} of len {len(X_validation)}\")\n",
    "        # train the model on training set\n",
    "        training_set = pd.concat(axis=1,objs=[X_train, y_train])\n",
    "        model.build_decision_tree(training_set)\n",
    "        \n",
    "        # run prediction on validation set\n",
    "        validation_set = pd.concat(axis=1,objs=[X_validation, y_validation])\n",
    "        predicted_labels = model.predict(validation_set)\n",
    "\n",
    "        # compute f1 score and store the best one\n",
    "        f1 = f1_score(y_validation, predicted_labels, labels=['+', '-'], pos_label='+')\n",
    "        print(f\"Fold {i} model has F1 Score: {f1}\")\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = model\n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb37d7d-3602-4c0e-9f85-13571b595c16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 model has F1 Score: 0.7692307692307692\n",
      "Fold 1 model has F1 Score: 0.7659574468085107\n",
      "Fold 2 model has F1 Score: 0.7916666666666667\n",
      "Fold 3 model has F1 Score: 0.7659574468085107\n",
      "Fold 4 model has F1 Score: 0.7272727272727272\n",
      "Fold 5 model has F1 Score: 0.8571428571428572\n",
      "Fold 6 model has F1 Score: 0.823529411764706\n",
      "Fold 7 model has F1 Score: 0.8076923076923077\n",
      "Fold 8 model has F1 Score: 0.847457627118644\n",
      "Fold 9 model has F1 Score: 0.7346938775510203\n"
     ]
    }
   ],
   "source": [
    "from decision_tree import DecisionTreeNode\n",
    "\n",
    "c45_tree = DecisionTreeNode(algorithm=\"C4.5\")\n",
    "best_c45, c45_score = sequentially_cross_validate(c45_tree, clean_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edbe11d4-9f67-4578-9401-b2e04f5d9e8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 model has F1 Score: 0.7317073170731708\n",
      "Fold 1 model has F1 Score: 0.72\n",
      "Fold 2 model has F1 Score: 0.7727272727272727\n",
      "Fold 3 model has F1 Score: 0.7659574468085107\n",
      "Fold 4 model has F1 Score: 0.7441860465116279\n",
      "Fold 5 model has F1 Score: 0.84\n",
      "Fold 6 model has F1 Score: 0.6938775510204083\n",
      "Fold 7 model has F1 Score: 0.8260869565217391\n",
      "Fold 8 model has F1 Score: 0.7200000000000001\n",
      "Fold 9 model has F1 Score: 0.6909090909090909\n"
     ]
    }
   ],
   "source": [
    "cart_tree = DecisionTreeNode(algorithm=\"CART\")\n",
    "best_cart, cart_score = sequentially_cross_validate(cart_tree, clean_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22393f32-6ee4-45fe-ba62-de9063990bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7538461538461538"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_c45_predictions = best_c45.predict(clean_test)\n",
    "c45_f1 = f1_score(test_labels, best_c45_predictions, labels=['+', '-'], pos_label='+')\n",
    "c45_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d4c24b1-1fc4-4ed7-964d-6081c5b0a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7931034482758621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cart_predictions = best_cart.predict(clean_test)\n",
    "cart_f1 = f1_score(test_labels, best_cart_predictions, labels=['+', '-'], pos_label='+')\n",
    "cart_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c64c3f-3742-4f33-b675-af92a34ee42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
